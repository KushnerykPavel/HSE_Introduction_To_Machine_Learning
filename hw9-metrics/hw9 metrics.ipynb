{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    1. Загрузите файл classification.csv. В нем записаны истинные классы объектов выборки (колонка true) \n",
    "    и ответы некоторого классификатора (колонка pred).\n",
    "'''\n",
    "\n",
    "df = pd.read_csv('classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 34 59 64\n",
      "0.54 0.56 0.42 0.48\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    2. Заполните таблицу ошибок классификации:\n",
    "        Actual Positive     Actual    Negative\n",
    "        Predicted Positive  TP        FP\n",
    "        Predicted Negative  FN        TN\n",
    "    Для этого подсчитайте величины TP, FP, FN и TN согласно их определениям. Например,\n",
    "    FP — это количество объектов, имеющих класс 0, но отнесенных алгоритмом к классу 1.\n",
    "    Ответ в данном вопросе — четыре числа через пробел.\n",
    "'''\n",
    "\n",
    "TP = sum([df['true'][i] == df['pred'][i] and df['pred'][i] == 1 for i in range(len(df))])\n",
    "TN = sum([df['true'][i] == df['pred'][i] and df['pred'][i] == 0 for i in range(len(df))])\n",
    "FP = sum([df['true'][i] != df['pred'][i] and df['pred'][i] == 1 for i in range(len(df))])\n",
    "FN = sum([df['true'][i] != df['pred'][i] and df['pred'][i] == 0 for i in range(len(df))])\n",
    "\n",
    "accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1_score_num = 2 * precision * recall / (precision + recall)\n",
    "print(TP, FP, FN, TN)\n",
    "print(round(accuracy, 2),round(precision, 2),round(recall, 2),round(f1_score_num, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54 0.56 0.42 0.53\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    3. Посчитайте основные метрики качества классификатора:\n",
    "\n",
    "    Accuracy (доля верно угаданных) — sklearn.metrics.accuracy_score\n",
    "    Precision (точность) — sklearn.metrics.precision_score\n",
    "    Recall (полнота) — sklearn.metrics.recall_score\n",
    "    F-мера — sklearn.metrics.f1_score\n",
    "    В качестве ответа укажите эти четыре числа через пробел.\n",
    "'''\n",
    "\n",
    "X = np.array(df['true'])\n",
    "y = np.array(df['pred'])\n",
    "\n",
    "accuracy_sklearn = accuracy_score(X,y)\n",
    "precision_sklearn = precision_score(X,y)\n",
    "recall_sklearn = recall_score(X,y)\n",
    "f1_score_sklearn = f1_score(X,y,average='macro')\n",
    "\n",
    "print(round(accuracy_sklearn, 2),round(precision_sklearn, 2),round(recall_sklearn, 2),round(f1_score_sklearn, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    4. Имеется четыре обученных классификатора. В файле scores.csv записаны истинные классы и значения степени \n",
    "    принадлежности положительному классу для каждого классификатора на некоторой выборке:\n",
    "\n",
    "    для логистической регрессии — вероятность положительного класса (колонка score_logreg),\n",
    "    для SVM — отступ от разделяющей поверхности (колонка score_svm),\n",
    "    для метрического алгоритма — взвешенная сумма классов соседей (колонка score_knn),\n",
    "    для решающего дерева — доля положительных объектов в листе (колонка score_tree).\n",
    "    Загрузите этот файл.\n",
    "'''\n",
    "\n",
    "df1 = pd.read_csv('scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.71918767507002801,\n",
       " 0.70868347338935567,\n",
       " 0.63515406162464982,\n",
       " 0.69192677070828335)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    5. Посчитайте площадь под ROC-кривой для каждого классификатора. Какой классификатор имеет наибольшее значение\n",
    "    метрики AUC-ROC (укажите название столбца)? Воспользуйтесь функцией sklearn.metrics.roc_auc_score. \n",
    "'''\n",
    "\n",
    "\n",
    "y_true = np.array(df1['true'])\n",
    "X_score_logreg = np.array(df1['score_logreg'])\n",
    "X_score_svm = np.array(df1['score_svm'])\n",
    "X_score_knn = np.array(df1['score_knn'])\n",
    "X_score_tree = np.array(df1['score_tree'])\n",
    "\n",
    "S_score_logreg = roc_auc_score(y_true, X_score_logreg)\n",
    "S_score_svm = roc_auc_score(y_true, X_score_svm)\n",
    "S_score_knn = roc_auc_score(y_true, X_score_knn)\n",
    "S_score_tree = roc_auc_score(y_true,X_score_tree)\n",
    "\n",
    "S_score_logreg, S_score_svm, S_score_knn, S_score_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    6. Какой классификатор достигает наибольшей точности (Precision) при полноте (Recall) не менее 70% ?\n",
    "'''\n",
    "\n",
    "precision_score_logreg, recall_score_logreg, thresholds_score_logreg = precision_recall_curve(y_true, X_score_logreg)\n",
    "precision_score_svm, recall_score_svm, thresholds_score_svm = precision_recall_curve(y_true, X_score_svm)\n",
    "precision_score_knn, recall_score_knn, thresholds_score_knn = precision_recall_curve(y_true, X_score_knn)\n",
    "precision_score_tree, recall_score_tree, thresholds_score_tree = precision_recall_curve(y_true, X_score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.63025210084033612,\n",
       " 0.6228070175438597,\n",
       " 0.60655737704918034,\n",
       " 0.6517857142857143)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(precision_score_logreg[recall_score_logreg>=0.7]), max(precision_score_svm[recall_score_svm>=0.7]),max(precision_score_knn[recall_score_knn>=0.7]),max(precision_score_tree[recall_score_tree>=0.7]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
